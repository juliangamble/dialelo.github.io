{"pages":[{"tags":"JavaScript","text":"People coming to React from other frameworks/libraries tend to ask themselves how to manage application state since React only solves the UI rendering problem, leaving the choice of state management and application architecture to the developer. Facebook suggest an architecture called Flux that fits with the React rendering model. In this article I will explore a way to manage state in JavaScript applications using React as their UI layer and recast Facebook's Flux conceptual framework using ideas from ClojureScript libraries like Om . Flux Flux's core idea is that data should flow in one direction . This makes reasoning about applications easier, dependencies between system components are well-defined and all state changes come from a \"single source of truth\", as they put it. In a nutshell: Views trigger Actions which are notified to Stores by a Dispatcher . Stores respond to actions modifying their state. Since views consume data from Stores and display it, Store updates trigger re-renders in the UI when needed. There are several things I dislike about Flux, namely: It complects state management and the bussiness logic for causing state changes. State is scattered through various stores which are apparently modular albeit they end up knowing about each other. The stores are coupled with the dispatching mechanism. From Stores to Global immutable state Instead of having multiple stores, I suggest Om's approach of having a global mutable reference to an immutable data structure. This way we model our application state as a succesion of immutable values, without modifying data in-place or rebinding variables to different values over time. This can be easily achieved using my atomo library and Facebook's immutable-js . The data structure contained in the global atom would be a map, which gives us the ability to split data into separate logical domains using keys. This approach doesn't try to hide the fact that separate logical domains tend to refer to each other, here is a contrived example of the shape of a music application state: // state.js import { fromJS } from \"immutable\" ; let initialState = fromJS ({ user : null , albums : [ { title : \"La Leyenda del Tiempo\" , artist : \"Camarón\" }, { title : \"Veneno\" , artist : \"Veneno\" } ], playlists : [ { name : \"Flamenco\" , tracks : [ { title : \"Nana del Caballo Grande\" , artist : \"Camarón\" , album : \"La Leyenda del Tiempo\" } ] } ] }); We can create the global mutable atom very easily from an immutable data structure: // state.js import atomo from \"atomo\" ; export const state = atomo . atom ( initialState ); Since atoms are observable and the immutable values they refer to share structure when creating a new, modified value out of them, we can serialize the states our application in a memory-efficient way: // history.js import { List } from \"immutable\" ; import { state } from \"./state\" ; const history = atomo . atom ( new List ()); state . addWatch ( function ( atom , oldValue , newValue ){ history . swap (( hs ) => hs . push ( oldValue )); }); This gives us the ability of time-travelling for free, it's trivial to implement undo/redo functionality on top of this state management strategy. If we were to serialize the succession of actions and their payload in the system we would be able to replay a user interaction with our application very easily, making regression testing as simple as feeding the aforementioned actions to the system and asserting that we end up with a consistent state. Cursors We don't want to be passing around all the state to every view. Views usually display a subset of the global state so we need the ability to focus on paths inside the global immutable state for making our views modular. Om solves this problem with an abstraction called Cursor , which lets us focus on a path of the global atom and offer the same API as atoms. This allows views to treat the substructure as their data source and even modify it with the same operations as the Atom. I wrote a simple implementation of this concept for using it with atoms and immutable data. We can derive a cursor from an atom or another cursor, allowing us to refine the path they point to: import kurtsore from \"kurtsore\" ; import { is } from \"immutable\" ; let cursor = kurtsore . cursor ( state ), albums = cursor . derive ( 'albums' ), playlists = cursor . derive ( 'playlists' ); is ( albums . deref (), state . deref (). get ( 'albums' ) ); //=> true is ( playlists . deref (), state . deref (). get ( 'playlists' ) ); //=> true Views We can create a cursor without a path for the top-level component, and refine it when passing it to sub-components. With this approach we can have modular views that represent a substructure of the global immutable state without knowing about the overall state. Since cursors save a snapshot of the state they point to when created and immutable data equality checks are blazing fast since they are just a reference comparison, they allow us to know whether a component should update and implement a very efficient shouldComponentUpdate . You can see an example in my react-kurtsore library and other open source libraries such as Omniscient . Here is an example of a component that displays a sub-component of the global state and passes refined cursors to its children: // views.js import React from \"react\" ; import { CursorPropsMixin } from \"react-kurtsore\" ; export const Album = React . createClass ({ mixins : [ CursorPropsMixin ], render (){ let album = this . props . album . deref (); return < li > { album . get ( 'artist' )} - { album . get ( 'title' )} < /li>; } }); export const Albums = React . createClass ({ mixins : [ CursorPropsMixin ], render (){ let albums = this . props . albums . deref (), cursors = albums . map (( a , idx ) => this . props . albums . derive ( idx )); return ( < ul > { cursors . map ( ( a , idx ) => < Album key = { idx } album = { a } /> )} < /ul> ); } }); Actions As in Flux, actions can be identified with unique and constant values. For this we can use strings or ES6 symbols. // constants.js export const ACTIONS = { LOG_IN : Symbol . for ( \"user:log-in\" ), LOG_IN_FAILED : Symbol . for ( \"user:log-in-failed\" ), LOG_OUT : Symbol . for ( \"user:log-out\" ) }; We represent actions as an immutable record with type and payload attributes, where the type is the identifier constant and the payload can be an arbitrary immutable value. // actions.js import immutable from \"immutable\" ; export const Action = immutable . Record ({ type : null , payload : null }); export function action ( type , payload ){ return new Action ({ type , payload }); }; Getting rid of the dispatcher Flux proposes the singleton Dispatcher coupled to stores for triggering state transitions. This introduces dependencies between stores, making them know about each other and the order the actions must be processed by each store. Dispatchers are also different from a pub-sub mechanism in that they fan-out every action that is triggered on them to all the stores. I instead suggest using CSP channels for the actions pub-sub mechanism, which you get with the js-csp library. The pub-sub system has a channel in which actions are published, and we can derive a publication from it. The publication takes the source channel and a function that extracts the \"topic\" of the messages put into the source channel. For ease of testing we can make the source channel configurable using an atom: // pubsub.js import atomo from \"atomo\" ; import csp from \"js-csp\" ; export const source = atomo . atom ( csp . chan ()); export function publication ( topicFn ){ return csp . operations . pub . publication ( source . deref (), topicFn ); }; export function publish ( msg ){ csp . putAsync ( source . deref (), msg ); }; The publication allows other components of the system to subscribe to a topic, providing a channel where the values that share the given topic will be put. We can subscribe to actions with the approach shown below: import csp from \"js-csp\" ; import pubsub from \"./pubsub\" ; import { ACTIONS } from \"./constants\" ; let userChan = csp . chan (), pub = pubsub . publication (( v ) => v . get ( \"type\" )); pub . sub ( ACTIONS . LOG_IN , userChan ); pub . sub ( ACTIONS . LOG_OUT , userChan ); csp . go ( function * (){ let action = yield userChan ; while ( action !== csp . CLOSED ) { let { type } = action ; if ( type === ACTIONS . LOG_IN ) { let user = action . get ( \"payload\" ); console . log ( user , \" just logged in.\" ) } else { console . log ( \"The user just logged out.\" ); } action = yield userChan ; } }); The userChan above is channel that will receive log-in and log-out actions published to the system; the generator passed to go will run indefinitely, listening for the actions that userChan receives and logging those events to the console. Note that the generator passed to go will only resume when userChan has values available, so it's safe to use a while loop inside it. Publishing actions Since some actions may require asynchronous computations to get the data they need and for the sake of decoupling views from the actions and the dispatch machinery, we encapsulate action triggering in high-level APIs that the views can consume. Flux calls this high-level APIs action creators. I suggest to encapsulate every action publication in one of these functions instead of publishing actions from the views themselves because it decouples views from the system's communication machinery. We also gain the benefit of testing views in isolation since we can interact with them and make sure they consume our high-level APIs in the way they are supposed to. // authentication.js import { ACTIONS } from \"./constants\" ; import { action } from \"./actions\" ; import pubsub from \"./pubsub\" ; import http from \"./http\" ; import { fromJS } from \"immutable\" ; export function tryLogIn ( username , password ){ http . post ( \"/login\" , { username , password }) . then (( user ) => pubsub . publish ( action ( ACTIONS . LOG_IN , fromJS ( user )))) . catch (( errors ) => pubsub . publish ( action ( ACTIONS . LOG_IN_FAILED , fromJS ( errors )))) }; export function logout ( username , password ){ pubsub . publish ( action ( ACTIONS . LOG_OUT )); }; Interpreting actions Having a pub-sub mechanism in place allows us to encapsulate state transitions into small pieces. These can listen for specific actions (or combinations of actions) on the pub-sub and affect the state accordingly, isolating bussines logic into modular and testable units I call effects . // effects.js import csp from \"js-csp\" ; import { ACTIONS } from \"./constants\" ; export function logIn ( publication , state ){ let loginChan = csp . chan (); publication . sub ( ACTIONS . LOG_IN , loginChan ); csp . go ( function * (){ let action = yield loginChan ; while ( action !== csp . CLOSED ) { let user = action . get ( \"payload\" ); state . swap (( st ) => st . set ( 'user' , user )) action = yield loginChan ; } }); return loginChan ; }; export function logOut ( publication , state ){ let logoutChan = csp . chan (); publication . sub ( ACTIONS . LOG_OUT , logoutChan ); csp . go ( function * (){ let action = yield logoutChan ; while ( action !== csp . CLOSED ) { state . swap (( st ) => st . remove ( 'user' )) action = yield logoutChan ; } }); return logoutChan ; }; We can test logIn and logOut effects in isolation inyecting a publication and an atom. Note that the logIn and logOut effects are started when calling them and return the channel they listen to, giving us the ability to shut them down closing the channel. If we group together a set of effects we could create a stateful object that allowed us to start and stop them at will. // effects.js class Effects { start ( publication , state ){ this . chans = [ logIn ( publication , state ), logOut ( publication , state ) ]; }, stop (){ this . chans . map (( ch ) => ch . close ()); } } export default new Effects (); Putting it all together With all of the above, here is an example of how the entry point of an application could look like: // main.js import React from \"react\" ; import { CursorPropsMixin } from \"react-kurtsore\" ; import { state } from \"./state\" ; import { Albums , Playlists } from \"./views\" ; import pubsub from \"./pubsub\" ; import effects from \"./effects\" ; const App = React . createClass ({ mixins : [ CursorPropsMixin ], render (){ let state = this . props . state ; return ( < div > < Albums state = { state . derive ( 'albums' )} /> < Playlists state = { state . derive ( 'playlists' )} /> < /div> ); } }); function render ( state ){ React . render ( < App state = { state } /> , document . querySelector ( \"body\" )); }; ( function bootstrap (){ // View render ( kurtsore . cursor ( state )); state . addWatch (() => render ( kurtsore . cursor ( state ))); // Pub-sub let publication = pubsub . publication (( ac ) => ac . get ( \"type\" )); // Effects effects . start ( publication , state ); })(); Further reading The Future of JavaScript MVC Frameworks Time Travel ES6 Generators and CSP Taming the Asynchronous Beast with CSP Channels in JavaScript","loc":"http://dialelo.github.io/application-architecture-with-react-rethinking-flux.html","title":"Application Architecture with React: rethinking Flux"},{"tags":"JavaScript","text":"In a previous post I wrote an introduction to CSP in JavaScript , where we learned that channels in CSP serve two purposes: conveyance of values and synchronization. I mentioned that several synchronization semantics can be achieved through the use of buffers but we didn't go into detail about that. This post will explore channel internals and the synchronization strategies through buffers in CSP usign the js-csp library. Channel internals In this section we'll understand the internals of a CSP channel as found in core.async or js-csp libraries, and learn about their method of operation. This information will help us understand buffering better and make more informed decissions about the buffering strategies we choose. A channel is an queue-like object where three operations can be performed: put, take and close. Only one value at a time can be put or taken. Internally, a channel encapsulates: A boolean flag ( closed ) that indicates whether is closed or not. A buffer where the data that is \"put\" will be stored waiting to be delivered to the takers. Two queues for storing the pending put and take operations. A transducer for transforming the values that are put into the channel. There are also some invariants that a channel must preserve, namely: There shouldn't be both pending puts and takes at the same time. If the buffer contains any data, a take shouldn't be queued in the pending queue. If there is room in the buffer, a put shouldn't be queued in the pending queue. We will forget about the transducer part for now since I will write about that in an upcoming post. Let's learn about how channels work under the hood when doing puts and takes. put When performing a put operation in a channel, we can encounter the channel in one of these three states: There are pending takes (hence no pending puts nor data in the buffer). There is room in the buffer (hence no pending puts nor pending takes). There isn't room in the buffer (hence no pending takes but possibly pending puts). For each of those states the channel will behave differently, preserving the invariants outlined above. If there are pending takes, the put operation will complete immediately and the value will be delivered to the first pending taker. If there is room in the buffer, the put operation will also complete immediately and the value will be added to the buffer. If there isn't room in the buffer, the put operation will be queued in the queue of pending puts. The third case is the only one in which the put operation \"blocks\" because it can't be performed immediately. take When performing a take operation in a channel, we can encounter the channel in one of three states analogous to those we described earlier for put operations: There are pending puts (hence no pending takes and a full buffer). There are no pending puts but there is data in the buffer (hence no pending takes). There are pending takes (hence no pending puts and an empty buffer). As with puts, for each of those states the channel will behave differently, preserving its invariants. If the buffer is full, the take operation will complete immediately taking the first value of the buffer. This will cause a pending put (if any) to complete putting its value in the buffer. If there is data in the buffer but no pending puts, the take operation will complete immediately taking the first value of the buffer. If there isn't any data in the buffer, the take operation will be queued in the queue of pending takes. Buffers As I mentioned in the previous post, buffers synchronize put and take operations inside a channel. When creating a channel with js-csp 's chan constructor and not providing a buffer, the channel will be unbuffered. This means that put operations won't succeed until a take operation comes in and viceversa. Here is an example of synchronization with a unbuffered channel: import { chan , take , put , go , timeout } from \"js-csp\" ; let unbufferedChan = chan (); go ( function * (){ yield put ( unbufferedChan , 42 ); console . log ( \"put completed!\" ); yield put ( unbufferedChan , 42 ); console . log ( \"put completed!\" ); }); go ( function * (){ console . log ( \"waiting a second\" ); yield timeout ( 1000 ); yield unbufferedChan ; console . log ( \"take completed!\" ); }); //=> \"waiting a second\" //=> \"take completed!\" //=> \"put completed!\" As we can see from the logged sentences, a put and a take must rendezvous for them to complete. Fixed The chan constructor accepts passing in either a number or a buffer. When we give it a number, a fixed buffer of that size will be created. This two calls are equivalent: import { chan , buffers } from \"js-csp\" ; chan ( 1 ); chan ( buffers . fixed ( 1 )) Having a fixed buffer means that, while there is room in the buffer, the put operations will succeed. Let's see an example of how a fixed buffer behaves with an example similar to the previous one: import { chan , take , put , go , timeout } from \"js-csp\" ; let fixedBufferChan = chan ( 1 ); go ( function * (){ yield put ( fixedBufferChan , 42 ); console . log ( \"first put completed!\" ); yield put ( fixedBufferChan , 42 ); console . log ( \"second put completed!\" ); }); go ( function * (){ console . log ( \"waiting a second\" ); yield timeout ( 1000 ); yield fixedBufferChan ; console . log ( \"take completed!\" ); }); //=> \"first put completed!\" //=> \"waiting a second\" //=> \"take completed!\" //=> \"second put completed!\" As you can see, a channel with a fixed buffer and no pending takes can accept up to n puts that will be completed immediately before queueing put operations, where n is the size of the fixed buffer. Dropping The following two buffer types always accept values so if you use them you'll never have pending puts. They differ in how they handle the overflow of values, since both are bounded. A dropping buffer of size n will hold at most n elements and will always accept new values. When we add a value to a dropping buffer and it has n elements, it will drop the value we just added, efectively dropping it. Let's see an example: import { chan , take , put , go , timeout , buffers } from \"js-csp\" ; let droppingBufferChan = chan ( buffers . dropping ( 2 )); go ( function * (){ yield put ( droppingBufferChan , 42 ); console . log ( \"first put completed!\" ); yield put ( droppingBufferChan , 43 ); console . log ( \"second put completed!\" ); yield put ( droppingBufferChan , 44 ); console . log ( \"third put completed!\" ); }); go ( function * (){ console . log ( \"waiting a second\" ); yield timeout ( 1000 ); console . log ( \"take completed:\" , yield droppingBufferChan ); console . log ( \"take completed:\" , yield droppingBufferChan ); console . log ( \"take completed:\" , yield droppingBufferChan ); }); //=> \"first put completed!\" //=> \"second put completed!\" //=> \"third put completed!\" //=> \"waiting a second\" //=> \"take completed: 42\" //=> \"take completed: 43\" As you can see, all puts got accepted immediately but only the first two made it into the channel's buffer. When trying to take a third value from the channel in the second goroutine, the operation didn't succeed and \"blocked\". Sliding A sliding buffer of size n will hold at most n elements and will always accept new values. When we add a value to a sliding buffer and it has n elements it will drop the oldest value that got added, so the buffer is a bounded window of values. Let's see an example: import { chan , take , put , go , timeout , buffers } from \"js-csp\" ; let slidingBufferChan = chan ( buffers . sliding ( 2 )); go ( function * (){ yield put ( slidingBufferChan , 42 ); console . log ( \"first put completed!\" ); yield put ( slidingBufferChan , 43 ); console . log ( \"second put completed!\" ); yield put ( slidingBufferChan , 44 ); console . log ( \"third put completed!\" ); }); go ( function * (){ console . log ( \"waiting a second\" ); yield timeout ( 1000 ); console . log ( \"take completed:\" , yield slidingBufferChan ); console . log ( \"take completed:\" , yield slidingBufferChan ); console . log ( \"take completed:\" , yield slidingBufferChan ); }); //=> \"first put completed!\" //=> \"second put completed!\" //=> \"third put completed!\" //=> \"waiting a second\" //=> \"take completed: 43\" //=> \"take completed: 44\" As you can see, all puts got accepted immediately but only the last two made it into the channel's buffer. When trying to take a third value from the channel in the second goroutine, the operation didn't succeed and \"blocked\". Promise The last buffer available in js-csp is the promise buffer. A promise buffer will always accept values, but only the first will be taken into account. Once the first value has been put, the buffer will always contain such element and takes on that channel will immediately succeed and return such value. It's analogous to the familiar Promise abstraction, where you only write one value that can be read many times. Let's see an example: import { chan , take , put , go , timeout , buffers } from \"js-csp\" ; let promiseBufferChan = chan ( buffers . promise ()); go ( function * (){ console . log ( \"waiting half a second\" ); yield timeout ( 500 ); yield put ( promiseBufferChan , 42 ); }); go ( function * (){ console . log ( \"waiting a quarter of a second\" ); yield timeout ( 250 ); yield put ( promiseBufferChan , 99 ); }); go ( function * (){ console . log ( \"waiting a second\" ); yield timeout ( 1000 ); console . log ( \"take completed:\" , yield promiseBufferChan ); console . log ( \"take completed:\" , yield promiseBufferChan ); console . log ( \"take completed:\" , yield promiseBufferChan ); }); //=> \"waiting half a second\" //=> \"waiting a quarter of a a second\" //=> \"waiting a second\" //=> \"take completed: 99\" //=> \"take completed: 99\" //=> \"take completed: 99\" As you can see, all the puts and takes succeeded. The first value that was put (99) was delivered to every taker. Further information js-csp 's documentation on channels Rich Hickey's talk about core.async channel internals Timothy Baldridge's video about core.async channel internals","loc":"http://dialelo.github.io/understanding-csp-channels-and-buffers.html","title":"Understanding CSP channels and buffers"},{"tags":"JavaScript","text":"The JavaScript programming language features a rich set of techniques for dealing with asynchronous computation. Raw Continuation Passing Style (CPS) with callbacks, promises and Functional Reactive Programming are commonplace in today's JS. EcmaScript 7 will bring syntantic sugar on top of promises with async and await and you can use that today with Babel . However, the Go and Clojure(Script) programming languages have popularized modern incarnations of Tony Hoare's Communicating Sequential Processes (CSP) , which is a great substrate for representing async computations and is backed by mathematical formalism. This article is intended as an introduction to CSP using the js-csp library, which is a straight port of the fantastic Clojure(Script) core.async . We'll explore the aforementioned alternatives and talk about their strengths and weaknesses. After that we'll delve into the building blocks of CSP: channels and processes; and show some examples of what you can do with such primitives. Continuation Passing Style The most common way of doing asynchronous computation in JavaScript has traditionally been continuation passing style, using callbacks for continuing async calls. This approach is prevalent in many of the APIs we use as JavaScript programmers, we can find examples in the browser, node and many existing libraries. The error handling is done either accepting an error argument in the continuation or providing two continuations, one for succesful results and another for errors. For a contrived example, let's assume that we have to make two calls to asynchronous functions, one called getUserToken for getting a authentication token and another to getUserInfo that needs to be authenticated with the token, we then log the user avatar URL to the console. Both functions accept success and error continuation as the last two arguments. import { getUserToken , getUserInfo } from \"./user-cps\" ; let username = \"Ada Byron\" , password = \"I invented programming\" ; let onError = ( err ) => console . error ( err ); getUserToken ( username , password , ( token ) => { getUserInfo ( token , ( userInfo ) => { console . log ( userInfo [ 'avatar' ]); }, onError ); }, onError ); Althoug our logic is very simple the callback machinery obscures it and the effort required to understand what's going on is a lot more than it should be. Continuation passing style is very low-level and I think that most people will agree that we need better abstractions on top of that. Luckily it's easy to transform functions written in continuation passing style to offer a nicer inteface. Promises Promises have slightly improved on CPS offering a first-class notion of asynchronous computations that may fail. There are many promise libraries available and since it has become so widespread ES6 is shipping them as part of the standard. If our getUserToken and getUserInfo function returned promises, we could transform the above example to this: import { getUserToken , getUserInfo } from \"./user-promises\" ; let username = \"Ada Byron\" , password = \"I invented programming\" ; getUserToken ( username , password ) . then (( token ) => getUserInfo ( token )) . then (( userInfo ) => { console . log ( userInfo [ 'avatar' ]); }) . catch (( err ) => console . error ( err )); Promises obscure our logic too since we have to scatter a logical piece of functionality in multiple unrelated small functions. On top of that, the then method complects map ping a transforming function over the value contained in a Promise with sequencing ( flatMap ) computations that return promises. async/await ES7's async and await keywords let us express asynchronous computations using promises in a much more clear way, solving the problem of obscured logic I talked before. We can declare a function as async and \"block\" for promises using the await keyword: import { getUserToken , getUserInfo } from \"./user-promises\" ; async function () { let username = \"Ada Byron\" , password = \"I invented programming\" ; try { let token = await getUserToken ( username , password ); let userInfo = await getUserInfo ( token ); console . log ( userInfo [ 'avatar' ]); } catch ( err ) { console . error ( err ); } } In my opinion this is much more clear and, as mentioned before, we can use it today with translators such as Babel . Reactive streams This is an unfair comparison since reactive streams represent a continuum of observable values instead of an asynchronous computation with a single value like promises. Streams are a great abstraction and you can manipulate them using a myriad of combinators, I recommend you to take a look at them. I'll be using Bacon.js for converting our CPS functions into streams: import Bacon from \"baconjs\" ; import { getUserToken , getUserInfo } from \"./user-cps\" ; let username = \"Ada Byron\" , password = \"I invented programming\" ; Bacon . fromCallback ( getUserToken , username , password ) . flatMap (( token ) => Bacon . fromCallback ( getUserInfo , token )) . map (( userInfo ) => userInfo [ 'avatar' ]) . log () . onError (( err ) => console . error ( err )) Streams still scatter our logic but they separate value transformation ( map ) from sequencing ( flatMap ), although it may depend on the implementation you are using. CSP I'll go into detail about CSP below but before that let's revisit our example. async and await are designed with promises in mind but we can get a similar syntactic abstraction using generators. Now our getUserToken and getUserInfo functions will return channels, and they will put the value computed asynchronously in the channels they return: import { go } from \"js-csp\" ; import { getUserToken , getUserInfo } from \"./user-csp\" ; go ( function * (){ let username = \"Ada Byron\" , password = \"I invented programming\" ; try { let token = yield getUserToken ( username , password ); let userInfo = yield getUserInfo ( token ); console . log ( userInfo [ 'avatar' ]); } catch ( err ) { console . error ( err ); } }); As you can see, it's fairly similar to the example of promises with async and await . Let's dive into the abstractions that CSP gives us for asynchronous computation to understand the above example better. Channels Channels are first class queue-like objects, multiple readers and writers can either take or put one value at a time on them. Their responsability is twofold: conveyance of values and synchronization. They decouple producers of values from consumers and are the message-passing primitive of CSP. Channels are unbuffered by default but we can create channels with different buffers, each with its own synchronization semantics. Let's explore channels and their operations: import { chan , putAsync , takeAsync } from \"js-csp\" ; let ch = chan (); takeAsync ( ch , ( value ) => console . log ( \"Got \" , value )); // `ch` now has a pending take, let's try putting a value in it putAsync ( ch , 42 ); //=> \"Got 42\" Puts and takes can happen in any order: import { chan , putAsync , takeAsync } from \"js-csp\" ; let ch = csp . chan (); // Async puts accept a callback too putAsync ( ch , 42 , () => console . log ( \"Just put 42\" )); putAsync ( ch , 43 , () => console . log ( \"One more\" )); takeAsync ( ch , ( value ) => console . log ( \"Got \" , value )) //=> \"Got 42\" //=> \"Just put 42\" takeAsync ( ch , ( value ) => console . log ( \"Got \" , value )) //=> \"Got 43\" //=> \"One more\" Channels can be closed and after closing them the pending puts will fail, whereas pending takes will receive a special value which signals that the channel is closed. Currently in js-csp such value is null so it's not allowed to put null into a channel. import { chan , takeAsync , putAsync , CLOSED } from \"js-csp\" ; let ch = chan (); takeAsync ( ch , ( value ) => console . log ( \"Channel closed? \" , value === CLOSED )); putAsync ( ch , 42 ); //=> \"Channel closed? false\" takeAsync ( ch , ( value ) => console . log ( \"Channel closed? \" , value === CLOSED )); takeAsync ( ch , ( value ) => console . log ( \"Channel closed? \" , value === CLOSED )); ch . close (); //=> \"Channel closed? true\" //=> \"Channel closed? true\" Processes The generator that we gave to the go function in the example above is a process , a piece of logic that uses channels for communication and synchronization. Puts and takes on a process will \"block\" until the operation completes, that's why we have to use yield when calling them. If we yield a channel an implicit take is performed. import { go , chan , put , take } from \"js-csp\" ; let ch = chan (); go ( function * (){ console . log ( \"[a] Starting a goroutine\" ); let value = yield take ( ch ); // equivalent to 'yield ch' console . log ( \"[a] Got \" , value ); }); go ( function * (){ console . log ( \"[b] Starting another goroutine\" ); yield put ( ch , 42 ); }); //=> \"[a] Starting a goroutine\" //=> \"[b] Starting another goroutine\" //=> \"[a] Got 42\" As we can see in the example above goroutines are a form of cooperative multitasking, they use channels for communication and channel operations for context switching. We can create thousands of these lightweight processes in our programs and coordinate via channels. Choice A cool thing about channels is that, given multiple channel operations, we can perform a non-determinismic choice between those operations. In the Go programming language such construct is called select , probably after POSIX's select system call, and in js-csp is a function called alts . An important thing to note is that only one of the operations given to alts will suceed and in case multiple operations are ready to be performed when calling it the successful operation will be chosen pseudo-randomly by default. Combined with js-csp 's timeout function, which returns a channel that won't receive any value and close after the given amount of milliseconds, we can execute operations on a channel given they can be performed fast enough: import { chan , go , timeout , put , alts } from \"js-csp\" ; let ch = chan (); go ( function * (){ console . log ( \"[a] Gonna sleep for a second\" ); yield timeout ( 1000 ); console . log ( \"[a] Now I'm ready to put a value\" ); yield put ( ch , 42 ); }); go ( function * (){ let cancel = timeout ( 300 ); // `alts` returns an object with the channel on which the operation has been // performed and its result let { channel , result } = yield alts ([ ch , cancel ]); if ( channel === cancel ) { console . log ( \"[b] Too slow, take was cancelled\" ); } else { console . log ( \"[b] Got \" , result ); } }); //=> \"[a] Gonna sleep for a second\" //=> \"[a] Now I'm ready to put a value\" //=> \"[b] Too slow, take was cancelled\" Conclusion We barely scratched the surface of what you can do with CSP in this article but I hope this introduction has served to get you excited about it. I plan to write more on the topic, there are many things that I didn't cover for the sake of brevity. I'm not claiming that CSP is superior to promises or reactive streams or that you should prefer it over them, it's about knowing the abstractions you can use for expressing asynchronous computations and choosing the one that fits the problem better and yields a simpler solution. In future articles I plan to cover more topics related to CSP in JavaScript, which will include: Buffering strategies Using transducers with channels High-level patterns on top of CSP UI component decoupling with channels CSP-flavored Functional Reactive Programming Further reading Taming the Async beast with ES7 Taming the Async beast with CSP in JavaScript Make no promises ES6 generators and CSP","loc":"http://dialelo.github.io/introduction-to-communicating-sequential-processes-in-javascript.html","title":"Introduction to Communicating Sequential Processes in JavaScript"}]}